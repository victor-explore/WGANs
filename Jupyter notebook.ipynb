{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch  # Import PyTorch library for deep learning operations\n",
    "import torch.nn as nn  # Import neural network module for building neural network architectures\n",
    "import torch.optim as optim  # Import optimization module for training neural networks\n",
    "from torchvision import datasets, transforms  # Import datasets and transforms for image processing\n",
    "from torch.utils.data import Dataset, DataLoader, random_split  # Import Dataset, DataLoader, and random_split for data handling\n",
    "from torchvision.utils import save_image, make_grid  # Import utility functions to save and display images\n",
    "import torchvision  # Import torchvision library for computer vision tasks\n",
    "import torchvision.models as models  # Import pre-trained models from torchvision\n",
    "import matplotlib.pyplot as plt  # Import plotting library for visualizations\n",
    "import os  # Import os module for file and directory operations\n",
    "import numpy as np  # Import numpy library for numerical operations\n",
    "from PIL import Image  # Import PIL for image processing\n",
    "import pathlib  # Import pathlib for file path operations\n",
    "import pandas as pd  # Import pandas for data manipulation and analysis\n",
    "import scipy  # Import scipy for scientific computing\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "from torch.optim.lr_scheduler import ExponentialLR  # Import ExponentialLR scheduler for learning rate decay\n",
    "from torch.nn.utils import spectral_norm  # Import spectral_norm for weight normalization in neural networks\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, Resize  # Import specific transform functions\n",
    "from torchvision.models import inception_v3  # Import Inception v3 model for FID calculation\n",
    "from scipy import linalg  # Import linalg from scipy for matrix operations in FID calculation\n",
    "from torch.nn.functional import adaptive_avg_pool2d  # Import adaptive average pooling for FID calculation\n",
    "from torchvision.models import inception_v3  # Import Inception v3 model for FID calculation\n",
    "from torchvision import transforms  # Import transforms for image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Set device\n",
    "print(f\"Using device: {device}\")  # Print the device being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the function returns batch_size number of noise vectors, each of dimension latent_dim. Scalar of each noise vector is sampled from a standard normal distribution with mean 0 and variance 1\n",
    "def sample_noise(batch_size, latent_dim=100): # The function takes two arguments: batch_size and latent_dim. batch_size is the number of noise vectors to generate, and latent_dim is the dimension of each noise vector.\n",
    "    \"\"\"\n",
    "    Generate noise vectors for the generator input.\n",
    "    \n",
    "    Args:\n",
    "        batch_size (int): The number of noise vectors to generate.\n",
    "        latent_dim (int): The dimension of each noise vector. Default is 100.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (batch_size, latent_dim, 1, 1) containing the generated noise vectors.\n",
    "    \"\"\"\n",
    "    noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)  # Generate random noise vectors from a standard normal distribution\n",
    "    return noise  # Return the generated noise tensor\n",
    "    noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)  #  torch.randn(), which generates a tensor of random numbers from a standard normal distribution (mean 0, variance 1)\n",
    "    return noise  # Return the noise tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator model class. It takes an input of dimension N x 100 x 1 x 1 ie a batch of noise vectors and outputs N x 3 x 128 x 128 ie a batch of images of dimension 3(RGB) x 128 x 128\n",
    "class Generator(nn.Module):  # Defined a class named Generator that inherits from nn.Module of PyTorch. nn.module is a class that defines a neural network in PyTorch\n",
    "\n",
    "    def __init__(self):  # Constructor function. Whenever an instance of the class is created, this function initializes the instance\n",
    "        super(Generator, self).__init__()  # Call parent constructor before any Generator specific initialization. This pattern ensures that all the benefits and functionalities provided by nn.Module are available to Generator, like parameter tracking, module moving to different devices (CPU/GPU), etc.\n",
    "        \n",
    "        self.main = nn.Sequential( # We define property of class called main, which is a ordered  ordered sequence of neural network layers. When we pass input through self.main, it goes through these layers in the order they are listed.\n",
    "            nn.ConvTranspose2d(in_channels=100, out_channels=512, kernel_size=4, stride=1, padding=0, bias=False),  # Input: N x 100 x 1 x 1, Output: N x 512 x 4 x 4, 512 filters of size 4x4x100\n",
    "            nn.BatchNorm2d(num_features=512),  # Batch normalization for 512 channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),  # Input: N x 512 x 4 x 4, Output: N x 256 x 8 x 8, 256 filters of size 4x4x512\n",
    "            nn.BatchNorm2d(num_features=256),  # Batch normalization for 256 channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),  # Input: N x 256 x 8 x 8, Output: N x 128 x 16 x 16, 128 filters of size 4x4x256\n",
    "            nn.BatchNorm2d(num_features=128),  # Batch normalization for 128 channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),  # Input: N x 128 x 16 x 16, Output: N x 64 x 32 x 32, 64 filters of size 4x4x128\n",
    "            nn.BatchNorm2d(num_features=64),  # Batch normalization for 64 channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1, bias=False),  # Input: N x 64 x 32 x 32, Output: N x 32 x 64 x 64, 32 filters of size 4x4x64\n",
    "            nn.BatchNorm2d(num_features=32),  # Batch normalization for 32 channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),  # Input: N x 32 x 64 x 64, Output: N x 3 x 128 x 128, 3 filters of size 4x4x32\n",
    "            nn.Tanh()  # Tanh activation to ensure output is in range [-1, 1]\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, input):  # Forward pass\n",
    "        return self.main(input)  \n",
    "    \n",
    "    def initialize_weights(self):  # Method to initialize weights of the Generator\n",
    "        for module in self.modules():  # Iterate through all modules in the Generator\n",
    "            if isinstance(module, (nn.ConvTranspose2d, nn.BatchNorm2d)):  # Check if the module is a ConvTranspose2d or BatchNorm2d layer\n",
    "                nn.init.normal_(module.weight.data, mean=0.0, std=0.02)  # Initialize weights with normal distribution (mean=0, std=0.02)\n",
    "                if module.bias is not None:  # If the module has a bias parameter\n",
    "                    nn.init.constant_(module.bias.data, 0.0)  # Initialize bias to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator model. The instance takes input of dimension N x 3 x 128 x 128 and outputs N x 1 tensor corresponding to f(x)\n",
    "class Discriminator(nn.Module):  # Discriminator class\n",
    "\n",
    "    def __init__(self):  # Constructor\n",
    "        super(Discriminator, self).__init__()  # Call parent constructor\n",
    "        self.main = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # LeakyReLU activation with negative slope of 0.2\n",
    "            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.BatchNorm2d(num_features=128),  # Batch normalization for 128 channels\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # LeakyReLU activation with negative slope of 0.2\n",
    "            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.BatchNorm2d(num_features=256),  # Batch normalization for 256 channels\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # LeakyReLU activation with negative slope of 0.2\n",
    "            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.BatchNorm2d(num_features=512),  # Batch normalization for 512 channels\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # LeakyReLU activation with negative slope of 0.2\n",
    "            spectral_norm(nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.BatchNorm2d(256),  # Batch normalization for 256 channels\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # Activation with negative slope of 0.2\n",
    "            spectral_norm(nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.BatchNorm2d(128),  # Batch normalization for 128 channels\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # Activation with negative slope of 0.2\n",
    "            spectral_norm(nn.Conv2d(in_channels=128, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False)),  # Apply spectral normalization to Conv2d layer\n",
    "            nn.Flatten()  # Flatten the output to N x 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):  # Forward pass\n",
    "        return self.main(input) \n",
    "\n",
    "    def weight_clip(self, clip_value=0.01): # Method to clip weights of the discriminator\n",
    "        for p in self.parameters(): # Iterate through all parameters of the discriminator\n",
    "            p.data.clamp_(-clip_value, clip_value) # Clips the weights to be within the range [-clip_value, clip_value]\n",
    "\n",
    "    def initialize_weights(self):  # Method to initialize weights of the discriminator\n",
    "        for module in self.modules():  # Iterate through all modules in the discriminator\n",
    "            if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):  # Check if the module is a Conv2d or BatchNorm2d layer\n",
    "                nn.init.normal_(module.weight.data, mean=0.0, std=0.02)  # Initialize weights with normal distribution\n",
    "                if module.bias is not None:  # Check if the module has a bias parameter\n",
    "                    nn.init.constant_(module.bias.data, 0.0)  # Initialize bias to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss for Wasserstein GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wasserstein GAN loss function is defined as:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_\\theta \\max_\\omega \\mathbb{E}_{x \\sim P_{data}}[f(x)] - \\mathbb{E}_{x \\sim P_{generator}}[f(x)]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\theta^*$ represents the optimal parameters of the generator\n",
    "- $\\theta$ are the generator parameters\n",
    "- $\\omega$ are the discriminator parameters\n",
    "- $f(x)$ is 1 - Lipschitz discriminator function\n",
    "- $P_{data}$ is the real data distribution\n",
    "- $P_{generator}$ is the generator's distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss Function\n",
    "\n",
    "The generator tries to minimize the following loss function:\n",
    "\n",
    "$$\n",
    "Loss = -\\mathbb{E}_{x \\sim P_{generator}}[f(x)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the output of the discriminator for the benerated image ie Batch size N x 1 values and returns the loss for generator\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"\n",
    "    Calculate the generator loss for Wasserstein GAN.\n",
    "    \n",
    "    Args:\n",
    "        fake_output (torch.Tensor): The output of the discriminator for batch of images generated by the generator.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The generator loss.\n",
    "    \"\"\"\n",
    "    return -torch.mean(fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss Function\n",
    "\n",
    "the discriminator tries to maximize the following loss function:\n",
    "\n",
    "$$\n",
    "Loss = -(\\mathbb{E}_{x \\sim P_{data}}[f(x)] - \\mathbb{E}_{x \\sim P_{generator}}[f(x)])\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the output of the discriminator for the real image and generated image\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    Calculate the discriminator loss for Wasserstein GAN.\n",
    "    \n",
    "    Args:\n",
    "        real_output (torch.Tensor): The output of the discriminator for a batch of real images.\n",
    "        fake_output (torch.Tensor): The output of the discriminator for a batch of fake images ie images generated by the generator.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The discriminator loss.\n",
    "    \"\"\"\n",
    "    return -(torch.mean(real_output) - torch.mean(fake_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5400 images.\n"
     ]
    }
   ],
   "source": [
    "class SimpleImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir  # Directory containing all images (including subfolders)\n",
    "        self.transform = transform  # Transformations to apply to images\n",
    "        self.image_files = []  # List to store all image file paths\n",
    "\n",
    "        # Traverse through all subfolders\n",
    "        for root, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.image_files.append(os.path.join(root, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)  # Return the total number of images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]  # Get image path\n",
    "        image = Image.open(img_path).convert('RGB')  # Open image and convert to RGB\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations if any\n",
    "        \n",
    "        return image  # Return only the image, no label needed for GAN\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize each RGB channel to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load the Animal dataset from local machine\n",
    "data_dir = r'D:\\Users\\VICTOR\\Desktop\\ADRL\\Assignment 1\\Animal_data_resized\\animals'  # Path to the Animal dataset\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = SimpleImageDataset(root_dir=data_dir, transform=transform)  # Use our simple dataset class\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)  # Create dataloader\n",
    "\n",
    "print(f\"Loaded {len(dataset)} images.\")  # Print the total number of images loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models and move to device\n",
    "generator = Generator().to(device) \n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTOR\\AppData\\Local\\Temp\\ipykernel_21788\\919218121.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  generator.load_state_dict(torch.load(generator_path))  # Load the saved state dictionary into the generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully and moved to device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTOR\\AppData\\Local\\Temp\\ipykernel_21788\\919218121.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  discriminator.load_state_dict(torch.load(discriminator_path))  # Load the saved state dictionary into the discriminator\n"
     ]
    }
   ],
   "source": [
    "# Define paths for saved models\n",
    "generator_path = r'D:\\Users\\VICTOR\\Desktop\\ADRL\\Assignment 1\\WGAN - Experiments\\3 Further trained 2\\saved_models_WGANs_butterfly\\generator_epoch_9.pth'  # Path to the saved generator model\n",
    "discriminator_path = r'D:\\Users\\VICTOR\\Desktop\\ADRL\\Assignment 1\\WGAN - Experiments\\3 Further trained 2\\saved_models_WGANs_butterfly\\discriminator_epoch_9.pth'  # Path to the saved discriminator model\n",
    "\n",
    "# Load the generator model\n",
    "generator = Generator().to(device)  # Create a new generator instance and move it to the device\n",
    "generator.load_state_dict(torch.load(generator_path))  # Load the saved state dictionary into the generator\n",
    "\n",
    "# Load the discriminator model\n",
    "discriminator = Discriminator().to(device)  # Create a new discriminator instance and move it to the device\n",
    "discriminator.load_state_dict(torch.load(discriminator_path))  # Load the saved state dictionary into the discriminator\n",
    "\n",
    "print(\"Models loaded successfully and moved to device.\")  # Print a success message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers and schedulers\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.0, 0.9))  # Optimizer for discriminator\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.0, 0.9))  # Optimizer for generator\n",
    "scheduler_d = ExponentialLR(optimizer_d, gamma=0.99)  # Learning rate scheduler for discriminator\n",
    "scheduler_g = ExponentialLR(optimizer_g, gamma=0.99)  # Learning rate scheduler for generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (16): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set models to training mode\n",
    "generator.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (17): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (18): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_epochs = 100 # Number of epochs for training\n",
    "noise_dim = 100 # Define the noise dimension\n",
    "clip_value = 0.01  # Clipping parameter\n",
    "n_critic = 1  # Number of critic iterations per generator iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Augmentation in GAN Training\n",
    "\n",
    "1. The `DiffAugment` function takes an input tensor `x` (typically a batch of images) and applies a series of augmentations based on the specified policy.\n",
    "\n",
    "2. The `policy` parameter is a string that can include 'color', 'translation', and 'cutout', separated by commas. These correspond to different types of augmentations.\n",
    "\n",
    "3. If the input tensor doesn't have channels as the first dimension (after batch size), it rearranges the dimensions.\n",
    "\n",
    "4. For each augmentation type specified in the policy:\n",
    "   - It retrieves the corresponding augmentation functions from the `AUGMENT_FNS` dictionary.\n",
    "   - It applies each of these functions to the input tensor `x`.\n",
    "\n",
    "5. The augmentation functions (defined elsewhere in the code) include:\n",
    "   - `rand_brightness`: Randomly adjusts brightness\n",
    "   - `rand_saturation`: Randomly adjusts saturation\n",
    "   - `rand_contrast`: Randomly adjusts contrast\n",
    "   - `rand_translation`: Randomly translates the image\n",
    "   - `rand_cutout`: Applies random cutouts to the image\n",
    "\n",
    "6. After applying all augmentations, it ensures the tensor is contiguous in memory and returns the augmented tensor.\n",
    "\n",
    "7. The key idea behind Differentiable Augmentation is that these augmentations are applied to both real and generated images during GAN training. This helps to regularize the discriminator and can significantly improve GAN performance, especially when training data is limited.\n",
    "\n",
    "8. By applying the same augmentations to both real and generated images, the discriminator is forced to focus on more robust features rather than potentially overfitting to specific details of the limited training data. This can lead to better generalization and more stable training, particularly in scenarios where the amount of training data is small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiable Augmentation for Data-Efficient GAN Training\n",
    "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
    "# https://arxiv.org/pdf/2006.10738\n",
    "# Code taken from: https://github.com/mit-han-lab/data-efficient-gans/blob/master/DiffAugment_pytorch.py\n",
    "\n",
    "def DiffAugment(x, policy='color,translation,cutout', channels_first=True):\n",
    "    \"\"\"\n",
    "    Apply differentiable augmentation to the input tensor.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor to be augmented.\n",
    "        policy (str): Comma-separated string specifying which augmentations to apply.\n",
    "        channels_first (bool): Whether the input tensor has channels as the first dimension.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Augmented tensor.\n",
    "    \"\"\"\n",
    "    if not x.is_cuda:  # Check if input tensor is on GPU\n",
    "        x = x.cuda()  # Move tensor to GPU if not already there\n",
    "    if policy:\n",
    "        if not channels_first:\n",
    "            x = x.permute(0, 3, 1, 2)  # Rearrange dimensions if channels are not first\n",
    "        for p in policy.split(','):\n",
    "            for f in AUGMENT_FNS[p]:\n",
    "                x = f(x)  # Apply each augmentation function specified in the policy\n",
    "        if not channels_first:\n",
    "            x = x.permute(0, 2, 3, 1)  # Rearrange dimensions back if necessary\n",
    "        x = x.contiguous()  # Ensure tensor is contiguous in memory\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_brightness(x):\n",
    "    \"\"\"\n",
    "    Apply random brightness augmentation to the input tensor.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor to be augmented.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Brightness-augmented tensor.\n",
    "    \"\"\"\n",
    "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)  # Add random brightness offset\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_saturation(x):\n",
    "    \"\"\"\n",
    "    Apply random saturation augmentation to the input tensor.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor to be augmented.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Saturation-augmented tensor.\n",
    "    \"\"\"\n",
    "    x_mean = x.mean(dim=1, keepdim=True)  # Calculate mean across color channels\n",
    "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1,\n",
    "                                   dtype=x.dtype, device=x.device) * 2) + x_mean  # Adjust saturation randomly\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_contrast(x):\n",
    "    \"\"\"\n",
    "    Apply random contrast augmentation to the input tensor.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor to be augmented.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Contrast-augmented tensor.\n",
    "    \"\"\"\n",
    "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)  # Calculate mean across all dimensions except batch\n",
    "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1,\n",
    "                                   dtype=x.dtype, device=x.device) + 0.5) + x_mean  # Adjust contrast randomly\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_translation(x, ratio=0.125):\n",
    "    \"\"\"\n",
    "    Apply random translation augmentation to the input tensor.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor to be augmented.\n",
    "        ratio (float): Maximum translation ratio relative to image size.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Translation-augmented tensor.\n",
    "    \"\"\"\n",
    "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)  # Calculate maximum shift\n",
    "    translation_x = torch.randint(-shift_x, shift_x + 1,\n",
    "                                  size=[x.size(0), 1, 1], device=x.device)  # Random horizontal shift\n",
    "    translation_y = torch.randint(-shift_y, shift_y + 1,\n",
    "                                  size=[x.size(0), 1, 1], device=x.device)  # Random vertical shift\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
    "    )  # Create meshgrid for indexing\n",
    "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)  # Apply horizontal shift\n",
    "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)  # Apply vertical shift\n",
    "    x_pad = torch.nn.functional.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])  # Pad input tensor\n",
    "    x = x_pad.permute(0, 2, 3, 1).contiguous()[\n",
    "        grid_batch, grid_x, grid_y].permute(0, 3, 1, 2).contiguous()  # Apply translation using grid sampling\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_cutout(x, ratio=0.5):\n",
    "    \"\"\"\n",
    "    Apply random cutout augmentation to the input tensor.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor to be augmented.\n",
    "        ratio (float): Size of the cutout relative to image size.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Cutout-augmented tensor.\n",
    "    \"\"\"\n",
    "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)  # Calculate cutout size\n",
    "    offset_x = torch.randint(0, x.size(\n",
    "        2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)  # Random x offset\n",
    "    offset_y = torch.randint(0, x.size(\n",
    "        3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)  # Random y offset\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
    "    )  # Create meshgrid for indexing\n",
    "    grid_x = torch.clamp(grid_x + offset_x -\n",
    "                         cutout_size[0] // 2, min=0, max=x.size(2) - 1)  # Calculate x coordinates of cutout region\n",
    "    grid_y = torch.clamp(grid_y + offset_y -\n",
    "                         cutout_size[1] // 2, min=0, max=x.size(3) - 1)  # Calculate y coordinates of cutout region\n",
    "    mask = torch.ones(x.size(0), x.size(2), x.size(3),\n",
    "                      dtype=x.dtype, device=x.device)  # Create mask tensor\n",
    "    mask[grid_batch, grid_x, grid_y] = 0  # Set cutout region to 0 in mask\n",
    "    x = x * mask.unsqueeze(1)  # Apply mask to input tensor\n",
    "    return x\n",
    "\n",
    "\n",
    "AUGMENT_FNS = {\n",
    "    'color': [rand_brightness, rand_saturation, rand_contrast],  # Color augmentation functions\n",
    "    'translation': [rand_translation],  # Translation augmentation function\n",
    "    'cutout': [rand_cutout],  # Cutout augmentation function\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation in GAN Training\n",
    "\n",
    "Augmentation Application\n",
    "- Both real and generated images are augmented using differentiable techniques before passing to the discriminator.\n",
    "- This creates a more challenging task for the discriminator.\n",
    "\n",
    "Discriminator Training\n",
    "- The discriminator now sees augmented versions of both real and fake images.\n",
    "- This increases difficulty in distinguishing between real and fake.\n",
    "\n",
    "Generator Training\n",
    "- The generator produces images as usual.\n",
    "- These images are then augmented before being passed to the discriminator.\n",
    "- Generator's loss is based on the discriminator's output on augmented fake images.\n",
    "\n",
    "Backpropagation\n",
    "- Differentiable augmentations allow gradients to flow through them.\n",
    "- Both generator and discriminator learn from the augmented data.\n",
    "\n",
    "Regularization Effect\n",
    "- Augmentation reduces overfitting to specific details in limited training data.\n",
    "- Encourages the discriminator to focus on more robust and general features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Batch 1/2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):  # Outer loop for every epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")  # Print for every epoch\n",
    "\n",
    "    for i, batch in enumerate(dataloader):  # Inner loop for every batch\n",
    "        print(f\"Batch {i+1}/{len(dataloader)}\")  # Print for every batch\n",
    "\n",
    "        # The batch is already the tensor of images\n",
    "        real_images = batch.to(device)  # Move the tensor to the device (GPU or CPU)\n",
    "        batch_size = real_images.size(0)  # Get batch size\n",
    "\n",
    "        # Train Discriminator\n",
    "        for _ in range(n_critic):  # Train discriminator more times than generator\n",
    "            optimizer_d.zero_grad()  # Reset gradients for the discriminator's parameters to zero\n",
    "            \n",
    "            # Apply DiffAugment to real images\n",
    "            augmented_real_images = DiffAugment(real_images, policy='color,translation,cutout').to(device)  # Move augmented images to device\n",
    "            real_output = discriminator(augmented_real_images)\n",
    "\n",
    "            noise = sample_noise(batch_size * len(augmented_real_images), noise_dim).to(device)  # Generate batch of noise vectors\n",
    "            fake_images = generator(noise)  # Pass the noise through the generator to generate fake images\n",
    "            \n",
    "            # Apply DiffAugment to fake images\n",
    "            augmented_fake_images = DiffAugment(fake_images.detach(), policy='color,translation,cutout').to(device)  # Move augmented images to device\n",
    "            fake_output = discriminator(augmented_fake_images)\n",
    "            \n",
    "            loss_d = discriminator_loss(real_output, fake_output)  # Calculate discriminator loss\n",
    "\n",
    "            loss_d.backward()  # Backpropagate discriminator loss\n",
    "            optimizer_d.step()  # Update discriminator weights\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()  # Reset the gradients of generator \n",
    "\n",
    "        noise = sample_noise(batch_size, noise_dim).to(device)  # Generate batch of noise vectors \n",
    "        fake_images = generator(noise)  # Pass the noise through the generator to generate fake images\n",
    "        \n",
    "        # Apply DiffAugment to fake images for generator training\n",
    "        augmented_fake_images = DiffAugment(fake_images, policy='color,translation,cutout').to(device)  # Move augmented images to device\n",
    "        fake_output = discriminator(augmented_fake_images)\n",
    "\n",
    "        loss_g = generator_loss(fake_output)  # Calculate generator loss\n",
    "\n",
    "        loss_g.backward()  # Backpropagate generator loss\n",
    "        optimizer_g.step()  # Update generator weights\n",
    "\n",
    "        # Print losses\n",
    "        print(f\"Discriminator loss: {loss_d.item():.4f}, Generator loss: {loss_g.item():.4f}\") \n",
    "\n",
    "        # Save generated images for every batch\n",
    "        generator.eval()\n",
    "        with torch.no_grad():  # Temporarily disables gradient computation\n",
    "            fake = fake_images[0].unsqueeze(0).cpu()\n",
    "            fake = (fake + 1) / 2.0  # Transform from [-1, 1] to [0, 1]\n",
    "            img = torchvision.utils.make_grid(fake, normalize=False)\n",
    "            img_np = img.detach().permute(1, 2, 0).numpy()\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(img_np)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Epoch {epoch+1}, Batch {i+1}\")\n",
    "            save_dir = r\"D:\\Users\\VICTOR\\Desktop\\ADRL\\Assignment 1\\generated_images_WGAN_animal\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir, f'generated_image_epoch_{epoch+1}_batch_{i+1}.png')\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "        generator.train()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Save generator and discriminator models after every epoch\n",
    "    save_dir = r\"D:\\Users\\VICTOR\\Desktop\\ADRL\\Assignment 1\\saved_models_WGANs_animal\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    generator_save_path = os.path.join(save_dir, f'generator_epoch_{epoch+1}.pth')\n",
    "    discriminator_save_path = os.path.join(save_dir, f'discriminator_epoch_{epoch+1}.pth')\n",
    "    torch.save(generator.state_dict(), generator_save_path)\n",
    "    torch.save(discriminator.state_dict(), discriminator_save_path)\n",
    "    print(f\"Models saved for epoch {epoch+1}\")\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler_d.step()  # Update discriminator learning rate\n",
    "    scheduler_g.step()  # Update generator learning rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalyticsEnvWindows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
